# ğŸš€ GenAI Hackathon: AI-Powered Startup Analysis Platform

## ğŸ“‹ Table of Contents
- [ğŸ¯ Overview](#overview)
- [âœ¨ Features](#features)
- [ğŸ¨ UI/UX Documentation](#ui-ux-documentation)
- [ğŸ—ï¸ Architecture](#architecture)
- [ğŸš€ Installation](#installation)
- [ğŸ“– Usage](#usage)
- [ğŸ“ Project Structure](#project-structure)
- [ğŸ”„ Data Flow](#data-flow)
- [ğŸ”§ API Reference](#api-reference)
- [âš™ï¸ Configuration](#configuration)
- [ğŸ” Troubleshooting](#troubleshooting)
- [ğŸ“Š Sample Data](#sample-data)

## ğŸ¯ Overview

**GenAI Hackathon** is an intelligent startup analysis platform that leverages AI to evaluate startups and provide investment insights. The system analyzes pitch decks, call transcripts, and other business documents to generate comprehensive scoring reports with actionable recommendations.

### ğŸ“‹ **Hackathon Documentation**
ğŸ”— **[Gen AI Exchange Hackathon Syncing Doc](https://docs.google.com/document/d/1Ll4_gXUX88Tt-9rIGWxXLOzS1FB-LyOw9NBrFh9YXA8/edit?usp=sharing)**

### ğŸª **Quick Demo**
```bash
ğŸš€ streamlit run app.py
```
ğŸŒ Visit `http://localhost:8501` to access the web interface.

---

## âœ¨ Features

### ğŸ” **Document Analysis**
- ğŸ“„ **Multi-format Support**: PDF, DOCX, TXT file processing
- ğŸ‘ï¸ **OCR Capabilities**: Extract text from scanned documents using Google Cloud Vision
- ğŸ§  **Intelligent Parsing**: AI-powered content extraction and structuring

### ğŸ“Š **Startup Scoring System**
- ğŸ¯ **8-Parameter Evaluation**: Comprehensive scoring across key business dimensions
- âš–ï¸ **Weighted Scoring**: Customizable weightage for different parameters
- ğŸ“ˆ **Benchmark Comparison**: Industry-specific performance benchmarks
- ğŸš¨ **Red Flag Detection**: Automated risk identification with page references

### ğŸ¨ **Interactive Dashboard**
- âš¡ **Real-time Analysis**: Live scoring updates as you modify parameters
- ğŸ“Š **Visual Analytics**: Interactive charts and trend analysis
- âœï¸ **Editable Data**: Modify scores and see instant impact on final rating
- ğŸ“¥ **Export Reports**: Download analysis results (coming soon)

### ğŸ¤– **AI Integration**
- ğŸ”® **Smart Extraction**: AI-powered parameter extraction from documents ğŸš§ **[PLANNED]**
- ğŸ’¡ **Recommendation Engine**: Contextual investment recommendations âœ… **[IMPLEMENTED]**
- âš ï¸ **Risk Assessment**: Intelligent risk factor identification âœ… **[IMPLEMENTED]**

---

## ğŸ¨ UI/UX Documentation

For detailed user interface and experience documentation, including:
- ğŸ“± **Component Structure**: Detailed breakdown of all UI components
- ğŸ¯ **User Journey Maps**: Complete user interaction flows
- ğŸ–¼ï¸ **Visual Design Guidelines**: Color schemes, typography, and layouts
- ğŸ“Š **Dashboard Components**: Interactive elements and data visualizations
- ğŸ”„ **State Management**: Session handling and real-time updates

ğŸ“– **See the complete [UI-UX Documentation](./UI-UX.md)**

---

## ğŸ—ï¸ Architecture

### ğŸ¯ **Frontend-Backend Separation**

The application follows a clear **Frontend-Backend architecture**:

- **ğŸ–¥ï¸ Frontend (`app.py`)**: Streamlit-based UI that handles user interactions, file uploads, and data visualization
- **âš™ï¸ Backend (`analyse_pipeline.py`)**: Core processing engine that performs analysis, scoring, and recommendation generation

```mermaid
graph TB
    subgraph FRONTEND["ğŸ–¥ï¸ FRONTEND - app.py"]
        UI[Streamlit UI]
        FU[File Upload Interface]
        DE[Data Editor]
        VIZ[Visualizations]
        BTN[Action Buttons]
    end
    
    subgraph BACKEND["âš™ï¸ BACKEND - analyse_pipeline.py"]
        CR[create_results]
        AR[analyze_results]
        DF[detect_red_flags]
        GR[generate_recommendations]
    end
    
    UI --> FU
    FU -->|Uploaded Files| CR
    CR -->|Results DataFrame| DE
    DE -->|Modified Data| AR
    AR -->|Updated Scores| VIZ
    BTN -->|Re-analyze| AR
    
    style UI fill:#4285f4,color:#fff
    style CR fill:#34a853,color:#fff
```

### ğŸ”„ **Complete Application Flow**

```mermaid
flowchart TD
    subgraph FRONTEND["ğŸ–¥ï¸ FRONTEND (app.py)"]
        START([User Opens App]) --> UPLOAD[File Upload UI]
        UPLOAD --> VALIDATE{Files Valid?}
        VALIDATE -->|No| ERROR[Show Error]
        VALIDATE -->|Yes| ANALYZE_BTN[Click Analyze Button]
        
        RESULTS_UI[Display Results Dashboard]
        EDIT_UI[Data Editor Interface]
        REANALYZE_BTN[Re-analyze Button]
    end
    
    subgraph BACKEND["âš™ï¸ BACKEND (analyse_pipeline.py)"]
        CREATE_RESULTS[create_results]
        ANALYZE_RESULTS[analyze_results]
        
        subgraph UTILS["ğŸ“š Utils Functions"]
            READ_FILES[read_files]
            CONTENT_JSON[content_to_json]
            CONVERT_STRUCT[convert_raw_to_structured]
        end
        
        subgraph ANALYSIS["ğŸ§  Analysis Functions"]
            DETECT_RED[detect_red_flags]
            DETECT_GREEN[detect_green_flags]
            GEN_REC[generate_recommendations]
        end
    end
    
    ANALYZE_BTN -->|Call| CREATE_RESULTS
    CREATE_RESULTS --> READ_FILES
    READ_FILES --> CONTENT_JSON
    CONTENT_JSON --> CONVERT_STRUCT
    CONVERT_STRUCT --> DETECT_RED
    CONVERT_STRUCT --> DETECT_GREEN
    DETECT_RED --> GEN_REC
    DETECT_GREEN --> GEN_REC
    
    CREATE_RESULTS -->|Return Results| RESULTS_UI
    RESULTS_UI --> EDIT_UI
    EDIT_UI --> REANALYZE_BTN
    REANALYZE_BTN -->|Call| ANALYZE_RESULTS
    ANALYZE_RESULTS -->|Update| RESULTS_UI
    
    style UPLOAD fill:#4285f4,color:#fff
    style CREATE_RESULTS fill:#34a853,color:#fff
    style ANALYZE_RESULTS fill:#fbbc05,color:#000
```

### ğŸ›ï¸ **High-Level System Overview**
```mermaid
graph LR
    A[ğŸ“„ Documents] --> B[ğŸ–¥ï¸ Frontend<br/>app.py]
    B --> C[âš™ï¸ Backend<br/>analyse_pipeline.py]
    C --> D[ğŸ§  Analysis Engine]
    D --> B
    B --> E[ğŸ“Š Interactive Dashboard]
```

### ğŸ“‹ **Key Function Calls Between Frontend & Backend**

| **Frontend Action (app.py)** | **Backend Function Called** | **Purpose** | **Returns** |
|------------------------------|----------------------------|------------|-------------|
| **User clicks "ğŸ” Analyze"** | `create_results(uploaded_files)` | Initial document analysis | summary_df, results_df, score, flags, recommendations |
| **User edits data in UI** | `analyze_results(structured_df)` | Re-calculate scores | final_score, flags, recommendations |
| **User clicks "ğŸ”„ Re-analyze"** | `analyze_results(structured_df)` | Refresh analysis | final_score, flags, recommendations |
| **Dashboard loads** | Uses returned DataFrames | Display results | N/A - uses stored session state |

### ğŸ”§ **Detailed Architecture Layers**

#### **ğŸ¨ Layer 1: Frontend User Interface (`app.py`)**
```mermaid
graph TB
    UI[Streamlit Web App - app.py]
    UP[File Upload - Lines 538-584]
    DA[Dashboard Display - Lines 749-823]
    ME[Metrics Display - Lines 589-640]
    IN[Insights Display - Lines 645-682]
    
    UI --> UP
    UI --> DA
    UI --> ME
    UI --> IN
```

#### **âš™ï¸ Layer 2: Backend Processing Pipeline (`analyse_pipeline.py`)**
```mermaid
graph LR
    INPUT[Input Files] --> CR[create_results - Lines 18-67]
    CR --> RF[read_files]
    RF --> PE[content_to_json]
    PE --> SC[convert_raw_to_structured]
    SC --> AR[analyze_results - Lines 151-167]
```

#### **ğŸ§  Layer 3: Analysis Engine (8 Parameters)**
```mermaid
graph TB
    SC[Scoring Engine] --> PARAMS{Parameter Analysis}
    
    PARAMS --> TS[Team Quality]
    PARAMS --> MS[Market Size]
    PARAMS --> TR[Traction]
    PARAMS --> FS[Financials]
    PARAMS --> PS[Product Uniqueness]
    PARAMS --> CS[Competition Analysis]
    PARAMS --> BS[Business Model]
    PARAMS --> RS[Risk Factors]
```

#### **ğŸ¤– Layer 4: Intelligence & Output**
```mermaid
graph TB
    SCORES[Parameter Scores] --> RF_ENGINE[Red Flag Detector]
    SCORES --> REC_ENGINE[Recommendation Engine]
    BENCH[Benchmarks] --> REC_ENGINE
    
    RF_ENGINE --> OUTPUT[Final Results]
    REC_ENGINE --> OUTPUT
    
    OUTPUT --> DASHBOARD[Return to Frontend]
```

### ğŸ§© Detailed Component Architecture

#### **ğŸ¨ 1. User Interface Layer** 
- **ğŸ–¥ï¸ [`Streamlit Web App`](./app.py)** - Main application interface
  - **ğŸ“¤ [File Upload Interface](./app.py#L18-L23)**: Multi-format document upload with validation
  - **ğŸ“Š [Interactive Dashboard](./app.py#L35-L89)**: Real-time results display and editing
  - **ğŸ“ˆ [Data Visualizations](./app.py#L78-L89)**: Charts, trends, and benchmark comparisons

#### **âš™ï¸ 2. Processing Pipeline Layer**
- **ğŸ”„ [`Main Pipeline`](./analyse_pipeline.py#L7-L55)** - Orchestrates entire analysis workflow
  - **ğŸ“– [`File Reader`](./Utils/utils.py#L42-L51)** - Batch processing of uploaded documents
  - **ğŸ” [`Parameter Extractor`](./Utils/pdf_file_reader.py#L15-L51)** - AI-powered content analysis
  - **ğŸ¯ [`Scoring Engine`](./Utils/structured_2_scored_data.py#L69-L146)** - Transforms text to numerical scores

#### **ğŸ§  3. Analysis Engine** - 8-Parameter Evaluation System
- **ğŸ‘¥ [`Team Scorer`](./Utils/structured_2_scored_data.py#L44-L51)** - Educational background + experience analysis
- **ğŸŒ [`Market Analyzer`](./Utils/structured_2_scored_data.py#L9-L24)** - TAM size evaluation with regex parsing
- **ğŸ“ˆ [`Traction Evaluator`](./Utils/structured_2_scored_data.py#L26-L42)** - User growth + MoM metrics
- **ğŸ’° [Financial Scorer](./Utils/structured_2_scored_data.py#L87)** - Revenue, ARR, burn rate assessment
- **ğŸš€ [Product Scorer](./Utils/structured_2_scored_data.py#L88)** - Innovation, differentiation, AI/tech analysis
- **ğŸ† [Competition Analyzer](./Utils/structured_2_scored_data.py#L89-L91)** - Market saturation and competitive positioning
- **ğŸ’¼ [Business Model Scorer](./Utils/structured_2_scored_data.py#L92)** - Revenue model clarity and scalability
- **âš ï¸ [Risk Assessor](./Utils/structured_2_scored_data.py#L93)** - Regulatory, operational, market risk evaluation

#### **ğŸ¤– 4. Intelligence Layer** - Advanced Analytics
- **ğŸš¨ [`Red Flag Detector`](./analyse_pipeline.py#L88-L110)** - Threshold-based risk identification
- **ğŸ’¡ [`Recommendation Engine`](./analyse_pipeline.py#L112-L118)** - Actionable insights generation
- **ğŸ“Š [`Benchmark Comparator`](./data/sector_benchmarks.csv)** - Industry-specific performance analysis

#### **ğŸ“š 5. Data Layer** - Information Management
- **ğŸ“„ Input Documents** - Multi-format file processing (PDF, DOCX, TXT)
- **ğŸ“Š Benchmark Data** - Sector-specific performance metrics
- **âš™ï¸ Configuration** - Parameter weights, thresholds, scoring rules
- **ğŸ“‹ Analysis Results** - Structured output with scores, flags, recommendations

---

### ğŸ”„ **Data Flow Architecture**

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant UI as ğŸ–¥ï¸ Streamlit UI
    participant P as âš™ï¸ Main Pipeline
    participant FR as ğŸ“– File Reader
    participant E as ğŸ” Parameter Extractor
    participant S as ğŸ¯ Scoring Engine
    participant A as ğŸ§  Analysis Engine
    participant I as ğŸ¤– Intelligence Layer
    
    U->>UI: ğŸ“¤ Upload Documents
    UI->>P: ğŸš€ Trigger Analysis
    P->>FR: ğŸ“„ Process Files
    FR->>E: ğŸ“Š Extract Content
    E->>S: ğŸ”„ Convert to Parameters
    S->>A: ğŸ¯ Apply Scoring Logic
    A->>I: ğŸ’¡ Generate Insights
    I->>UI: ğŸ“‹ Return Results
    UI->>U: ğŸ“Š Display Dashboard
    
    Note over U,I: âš¡ Real-time interaction loop
    U->>UI: âœï¸ Modify Parameters
    UI->>I: ğŸ”„ Recalculate
    I->>UI: ğŸ“ˆ Updated Results
```

---

### ğŸ”„ **Execution Flow**

#### **ğŸš€ Initial Analysis Flow** (When User Clicks "ğŸ” Analyse")

```mermaid
flowchart TD
    subgraph FRONTEND["ğŸ–¥ï¸ FRONTEND (app.py)"]
        START([User Clicks Analyse - Line 728]) --> VALIDATE{Pitch Deck Uploaded?<br/>Line 729}
        VALIDATE -->|No| ERROR[Show Error: Pitch Deck Required<br/>Line 730]
        VALIDATE -->|Yes| TRIGGER[Trigger Analysis<br/>Line 732]
        UPDATE_SESSION[Update Session State<br/>Lines 740-742]
        RERUN[st.rerun - Line 744]
        SHOW_DASHBOARD[Display Dashboard<br/>Lines 749-823]
    end
    
    subgraph BACKEND["âš™ï¸ BACKEND (analyse_pipeline.py)"]
        CALL_CREATE[create_results<br/>Line 18]
        READ_FILES[read_files<br/>Line 28]
        EXTRACT_PARAMS[content_to_json<br/>Line 31]
        CREATE_DF[Create DataFrame<br/>Line 34]
        FILTER_DF[Filter Parameters<br/>Lines 39-40]
        SCORE_CONVERT[convert_raw_to_structured<br/>Line 45]
        CALC_WEIGHTED[Calculate Weighted Scores<br/>Line 49]
        FINAL_SCORE[Sum Final Score<br/>Line 52]
        DETECT_FLAGS[detect_red_flags<br/>Line 57]
        GEN_RECS[generate_recommendations<br/>Line 61]
        RETURN_RESULTS[Return Results<br/>Line 67]
    end
    
    subgraph UTILS["ğŸ“š Utils Layer"]
        LOOP_FILES{For Each File}
        READ_SINGLE[read_file]
        CHECK_TYPE{File Type?}
        PDF_EXTRACT[PyPDF2 Extract]
        DOCX_EXTRACT[python-docx Extract]
        TXT_EXTRACT[UTF-8 Decode]
        SCORE_PARAMS{Score Each Parameter}
        TEAM_SCORE[parse_team]
        MARKET_SCORE[parse_market_size]
        TRACTION_SCORE[parse_traction]
    end
    
    TRIGGER -->|Line 739| CALL_CREATE
    CALL_CREATE --> READ_FILES
    READ_FILES --> LOOP_FILES
    LOOP_FILES --> READ_SINGLE
    READ_SINGLE --> CHECK_TYPE
    CHECK_TYPE -->|PDF| PDF_EXTRACT
    CHECK_TYPE -->|DOCX| DOCX_EXTRACT
    CHECK_TYPE -->|TXT| TXT_EXTRACT
    
    PDF_EXTRACT --> EXTRACT_PARAMS
    DOCX_EXTRACT --> EXTRACT_PARAMS
    TXT_EXTRACT --> EXTRACT_PARAMS
    
    EXTRACT_PARAMS --> CREATE_DF
    CREATE_DF --> FILTER_DF
    FILTER_DF --> SCORE_CONVERT
    SCORE_CONVERT --> SCORE_PARAMS
    
    SCORE_PARAMS --> TEAM_SCORE
    SCORE_PARAMS --> MARKET_SCORE
    SCORE_PARAMS --> TRACTION_SCORE
    
    TEAM_SCORE --> CALC_WEIGHTED
    MARKET_SCORE --> CALC_WEIGHTED
    TRACTION_SCORE --> CALC_WEIGHTED
    
    CALC_WEIGHTED --> FINAL_SCORE
    FINAL_SCORE --> DETECT_FLAGS
    DETECT_FLAGS --> GEN_RECS
    GEN_RECS --> RETURN_RESULTS
    
    RETURN_RESULTS -->|Line 739| UPDATE_SESSION
    UPDATE_SESSION --> RERUN
    RERUN --> SHOW_DASHBOARD
    
    ERROR --> END([End])
    SHOW_DASHBOARD --> END
    
    style START fill:#4285f4,color:#fff
    style CALL_CREATE fill:#34a853,color:#fff
    style RETURN_RESULTS fill:#fbbc05,color:#000
```

#### **ğŸ”„ Re-Analysis Flow** (When User Clicks "ğŸ”„ Analyse Again")

```mermaid
flowchart TD
    subgraph FRONTEND2["ğŸ–¥ï¸ FRONTEND (app.py)"]
        START([User Clicks Re-analyze<br/>Line 862]) --> TRIGGER[Button Click Event]
        UPDATE_SESSION[Update Session Variables<br/>Lines 865-867]
        RERUN[st.rerun - Line 870]
        UPDATED_DASHBOARD[Updated Dashboard Display<br/>Lines 749-823]
    end
    
    subgraph BACKEND2["âš™ï¸ BACKEND (analyse_pipeline.py)"]
        CALL_ANALYZE[analyze_results<br/>Line 151]
        GET_DF[Process DataFrame<br/>Line 153]
        RECALC_WEIGHTED[Recalculate Weighted Scores<br/>Line 154]
        NEW_FINAL[New Final Score<br/>Line 157]
        REFRESH_FLAGS[detect_red_flags<br/>Line 162]
        REFRESH_RECS[generate_recommendations<br/>Line 166]
    end
    
    TRIGGER -->|Line 864| CALL_ANALYZE
    CALL_ANALYZE --> GET_DF
    GET_DF --> RECALC_WEIGHTED
    RECALC_WEIGHTED --> NEW_FINAL
    NEW_FINAL --> REFRESH_FLAGS
    REFRESH_FLAGS --> REFRESH_RECS
    REFRESH_RECS -->|Return| UPDATE_SESSION
    UPDATE_SESSION --> RERUN
    RERUN --> UPDATED_DASHBOARD
    UPDATED_DASHBOARD --> END([End])
    
    style START fill:#4285f4,color:#fff
    style CALL_ANALYZE fill:#fbbc05,color:#000
```

#### **âœï¸ Interactive Parameter Editing Flow** (Real-time Updates)

```mermaid
flowchart TD
    subgraph FRONTEND3["ğŸ–¥ï¸ FRONTEND (app.py)"]
        START([User Edits in Data Editor<br/>Line 812]) --> STREAMLIT_UPDATE[Streamlit Auto-Update<br/>Line 819]
        SESSION_UPDATE[Session State Updated<br/>Line 819]
        DISPLAY_UPDATE[Display Updates]
    end
    
    subgraph BACKEND3["âš™ï¸ BACKEND (analyse_pipeline.py)"]
        CALL_ANALYZE[analyze_results<br/>Line 762]
        INSTANT_RECALC[Instant Recalculation<br/>Lines 153-167]
    end
    
    STREAMLIT_UPDATE --> SESSION_UPDATE
    SESSION_UPDATE --> CALL_ANALYZE
    CALL_ANALYZE --> INSTANT_RECALC
    INSTANT_RECALC --> DISPLAY_UPDATE
    DISPLAY_UPDATE --> END([Real-time UI Update])
    
    style START fill:#4285f4,color:#fff
    style CALL_ANALYZE fill:#34a853,color:#fff
```

#### **âš¡ Key Execution Points**

| **ğŸ¯ Execution Stage** | **ğŸ”§ Function Called** | **ğŸ“ File Location** |
|---------------------|-------------------|------------------|
| **ğŸ“¤ File Upload Validation** | File upload check | [`app.py:26-27`](./app.py#L26-L27) |
| **ğŸ“– File Content Reading** | [`read_files()`](./Utils/utils.py#L42-L51) | `Utils/utils.py` |
| **ğŸ” Parameter Extraction** | [`content_to_json()`](./Utils/pdf_file_reader.py#L15-L51) | `Utils/pdf_file_reader.py` |
| **ğŸ¯ Scoring Conversion** | [`convert_raw_to_structured()`](./Utils/structured_2_scored_data.py#L69-L146) | `Utils/structured_2_scored_data.py` |
| **ğŸ“Š Individual Parameter Scoring** | [`parse_team()`](./Utils/structured_2_scored_data.py#L44-L51), [`parse_market_size()`](./Utils/structured_2_scored_data.py#L9-L24), etc. | `Utils/structured_2_scored_data.py` |
| **ğŸ§® Final Score Calculation** | Weighted sum | [`analyse_pipeline.py:38-41`](./analyse_pipeline.py#L38-L41) |
| **ğŸš¨ Red Flag Detection** | [`detect_red_flags()`](./analyse_pipeline.py#L88-L110) | `analyse_pipeline.py` |
| **ğŸ’¡ Recommendation Generation** | [`generate_recommendations()`](./analyse_pipeline.py#L112-L118) | `analyse_pipeline.py` |
| **ğŸ“Š Dashboard Display** | Streamlit rendering | [`app.py:35-89`](./app.py#L35-L89) |

#### **âš ï¸ Error Handling Points**

- **ğŸ“¤ File Upload Validation** - [`app.py:26-28`](./app.py#L26-L28) - Missing pitch deck check
- **ğŸ“– File Reading Errors** - [`Utils/utils.py:30-31`](./Utils/utils.py#L30-L31) - DOCX processing exceptions  
- **ğŸ” Content Extraction** - [`Utils/pdf_file_reader.py`](./Utils/pdf_file_reader.py) - Malformed document handling
- **ğŸ¯ Scoring Validation** - [`Utils/structured_2_scored_data.py`](./Utils/structured_2_scored_data.py) - Invalid parameter values

---

## ğŸš€ Installation

### ğŸ“‹ **Prerequisites**
- ğŸ **Python 3.8+**
- ğŸ“¦ **pip package manager**
- â˜ï¸ **Google Cloud Vision API** (optional, for OCR)

### âš¡ **Quick Setup**
```bash
# ğŸ“¥ Clone the repository
git clone <repository-url>
cd GenAI_Hackathon

# ğŸ—ï¸ Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸš€ Run the application
streamlit run app.py
```

### ğŸ“š **Dependencies**
```
streamlit>=1.28.0     # ğŸ–¥ï¸ Web framework
pandas>=1.5.0         # ğŸ“Š Data manipulation
PyPDF2>=3.0.0         # ğŸ“„ PDF processing
python-docx>=0.8.11   # ğŸ“ Word document processing
google-cloud-vision>=3.4.0  # ğŸ‘ï¸ OCR (Optional)
numpy>=1.24.0         # ğŸ”¢ Numerical computing
```

---

## ğŸ“– Usage

### ğŸ“¤ **1. Document Upload**
```python
# ğŸ“‹ Supported file types
SUPPORTED_FORMATS = {
    'ğŸ“„ pdf': 'Pitch decks, financial reports',
    'ğŸ“ docx': 'Business plans, founder profiles', 
    'ğŸ“„ txt': 'Call transcripts, notes'
}
```

### ğŸ”„ **2. Analysis Process**
1. **ğŸ“¤ Upload Documents**: Drag and drop files (Pitch deck is mandatory)
2. **ğŸ” Click Analyze**: System processes documents and extracts parameters
3. **ğŸ“Š Review Results**: Interactive dashboard with scores and insights
4. **âœï¸ Modify Parameters**: Edit scores to see impact on final rating
5. **ğŸ“¥ Export Report**: Download comprehensive analysis (coming soon)

### ğŸ¯ **3. Scoring Parameters**

| **ğŸ“Š Parameter** | **âš–ï¸ Weight** | **ğŸ“‹ Description** | **ğŸ¯ Score Range** |
|-----------|--------|-------------|-------------|
| **ğŸ‘¥ Team Quality** | 15% | Educational background, experience | 1-10 |
| **ğŸŒ Market Size** | 15% | Total addressable market analysis | 1-10 |
| **ğŸ“ˆ Traction** | 15% | User growth, engagement metrics | 1-10 |
| **ğŸ’° Financials** | 10% | Revenue, profitability, burn rate | 1-10 |
| **ğŸš€ Product Uniqueness** | 15% | Innovation, differentiation | 1-10 |
| **ğŸ† Competitive Landscape** | 10% | Market competition analysis | 1-10 |
| **ğŸ’¼ Business Model Clarity** | 10% | Revenue model, scalability | 1-10 |
| **âš ï¸ Risk Factors** | 10% | Regulatory, operational risks | 1-10 |

---

## ğŸ“ Project Structure

```
ğŸš€ GenAI_Hackathon/
â”œâ”€â”€ ğŸ–¥ï¸ app.py                    # Main Streamlit application
â”œâ”€â”€ âš™ï¸ analyse_pipeline.py       # Core analysis pipeline
â”œâ”€â”€ ğŸ“‹ README.md                 # Main documentation (this file)
â”œâ”€â”€ ğŸ“ readme.md                 # Secondary readme file
â”œâ”€â”€ ğŸ“¦ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ __init__.py               # Python package initialization
â”‚
â”œâ”€â”€ ğŸ”§ Utils/                    # Utility modules
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils.py              # File processing utilities
â”‚   â”œâ”€â”€ ğŸ“„ pdf_file_reader.py    # PDF content extraction
â”‚   â”œâ”€â”€ ğŸ¯ structured_2_scored_data.py  # Scoring algorithms
â”‚   â””â”€â”€ ğŸ§® final_score.py        # Final score calculation
â”‚
â”œâ”€â”€ ğŸ› ï¸ tools/                    # Processing tools
â”‚   â”œâ”€â”€ ğŸ”¨ tools.py              # PDF processing tools
â”‚   â”œâ”€â”€ ğŸ’¬ prompts.py            # AI prompts and templates
â”‚   â””â”€â”€ ğŸ __init__.py           # Package initialization
â”‚
â”œâ”€â”€ ğŸ“Š data/                     # Data and benchmarks
â”‚   â”œâ”€â”€ ğŸ“ˆ sector_benchmarks.csv # Industry benchmarks
â”‚   â”œâ”€â”€ ğŸ“‹ data_extracted.json   # Sample extracted data
â”‚   â”œâ”€â”€ ğŸ”„ data_normalized.json  # Processed data samples
â”‚   â”œâ”€â”€ ğŸ“Š data_score.json       # Scored data results
â”‚   â”œâ”€â”€ ğŸ“ data_score_sample.json # Sample scoring data
â”‚   â””â”€â”€ ğŸ“ archieve/             # Historical data
â”‚       â””â”€â”€ ğŸ“‹ startup_parameters.csv
â”‚
â”œâ”€â”€ ğŸ“¤ input/                    # Sample documents
â”‚   â”œâ”€â”€ ğŸ“Š startup_ptch_deck.pdf # Main startup pitch deck
â”‚   â”œâ”€â”€ ğŸ“ˆ FinTechX_ AI-Powered SME Lending Revolution.pdf # FinTech example
â”‚   â”œâ”€â”€ ğŸ“ transcript.txt        # Call transcript sample
â”‚   â”œâ”€â”€ ğŸ“ pitch_deck_draft.txt  # Text-based pitch deck
â”‚   â”œâ”€â”€ ğŸ“§ email.docx            # Email communication sample
â”‚   â””â”€â”€ ğŸ‘¤ founder_material.docx # Founder background info
```

---

## ğŸ”„ Data Flow

### ğŸ“¤ **1. Input Processing**
**ğŸ“ File Upload & Validation**
- **ğŸ–¥ï¸ UI Components**: See [`app.py:18-23`](./app.py#L18-L23) for Streamlit file uploaders
- **ğŸ“– File Processing**: [`read_files()`](./Utils/utils.py#L42-L51) function in `Utils/utils.py`
- **ğŸ“„ Individual File Reading**: [`read_file()`](./Utils/utils.py#L8-L39) function in `Utils/utils.py`

**âš™ï¸ Supported Operations:**
- **ğŸ“„ PDF Processing**: PyPDF2-based text extraction ([`read_file()` lines 18-24](./Utils/utils.py#L18-L24))
- **ğŸ“ DOCX/DOC Processing**: python-docx integration ([`read_file()` lines 26-32](./Utils/utils.py#L26-L32)) 
- **ğŸ“„ TXT Processing**: UTF-8 decoding ([`read_file()` lines 34-35](./Utils/utils.py#L34-L35))

### ğŸ¤– **2. AI Analysis & Content Extraction** ğŸš§ **[PARTIALLY IMPLEMENTED]**
**ğŸ”„ Content Structure Conversion**
- **ğŸ§  Main Function**: [`content_to_json()`](./Utils/pdf_file_reader.py#L15-L51) ğŸš§ **[TO BE IMPLEMENTED]** - Currently uses sample data
- **ğŸ“Š DataFrame Creation**: See [`analyse_pipeline.py:23-28`](./analyse_pipeline.py#L23-L28) âœ… **[WORKING]** - Parameter extraction pipeline
- **ğŸ” Data Filtering**: Non-evaluating parameters removed ([lines 29-30](./analyse_pipeline.py#L29-L30)) âœ… **[WORKING]**

**ğŸ“‹ Output Format**: Structured JSON with company parameters (name, sector, team, market, traction, revenue, USP, competition, risks)
**âš ï¸ Note**: Currently uses hardcoded sample data - AI integration needed for production use

### ğŸ¯ **3. Scoring Pipeline**
**ğŸ”§ Parameter Scoring Functions** - All in [`Utils/structured_2_scored_data.py`](./Utils/structured_2_scored_data.py):
- **ğŸ‘¥ Team Quality**: [`parse_team()`](./Utils/structured_2_scored_data.py#L44-L51) function - IIT/IIM bonus scoring
- **ğŸŒ Market Size**: [`parse_market_size()`](./Utils/structured_2_scored_data.py#L9-L24) function - Billion/Million market analysis  
- **ğŸ“ˆ Traction**: [`parse_traction()`](./Utils/structured_2_scored_data.py#L26-L42) function - User growth and MoM metrics
- **ğŸ“Š Other Parameters**: [Lines 84-94](./Utils/structured_2_scored_data.py#L84-L94) for Financials, Product Uniqueness, Competition, etc.

**âš–ï¸ Weighted Calculation**:
- **ğŸ¯ Weights Definition**: [Lines 117-126](./Utils/structured_2_scored_data.py#L117-L126) in structured_2_scored_data.py
- **ğŸ§® Score Calculation**: [`analyse_pipeline.py:38-43`](./analyse_pipeline.py#L38-L43) for weighted final score

### ğŸ“Š **4. Analysis Output & Risk Detection**
**ğŸš¨ Red Flag Detection**
- **âš™ï¸ Function**: [`detect_red_flags()`](./analyse_pipeline.py#L88-L110) in `analyse_pipeline.py`
- **ğŸ¯ Logic**: Compares scores against thresholds with page references

**ğŸ’¡ Recommendation Engine**
- **âš™ï¸ Function**: [`generate_recommendations()`](./analyse_pipeline.py#L112-L118) in `analyse_pipeline.py`
- **ğŸ“‹ Output**: Parameter-specific actionable insights

---

## ğŸ”§ API Reference

### ğŸ”§ **Core Functions**

#### ğŸš€ [`create_results(uploaded_files)`](./analyse_pipeline.py#L7-L55)
*ğŸ“ Location: `analyse_pipeline.py:7-55`*

**ğŸ¯ Purpose**: Main analysis pipeline that processes uploaded files and generates comprehensive startup evaluation.

**ğŸ”„ Process Flow**:
1. ğŸ“– Extract content from files using [`read_files()`](./Utils/utils.py#L42-L51) 
2. ğŸ”„ Convert to structured JSON via [`content_to_json()`](./Utils/pdf_file_reader.py#L15-L51)
3. ğŸ“Š Create parameter DataFrame ([`create_results()` lines 23-28](./analyse_pipeline.py#L23-L28))
4. ğŸ¯ Apply scoring algorithms via [`convert_raw_to_structured()`](./Utils/structured_2_scored_data.py#L69-L146)
5. âš–ï¸ Calculate weighted scores and final rating
6. ğŸš¨ Generate red flags via [`detect_red_flags()`](./analyse_pipeline.py#L88-L110) and ğŸ’¡ recommendations via [`generate_recommendations()`](./analyse_pipeline.py#L112-L118)

**ğŸ“¥ Parameters**: `uploaded_files` - List of Streamlit file objects
**ğŸ“¤ Returns**: summary_df, results_df, final_score, flags, recommendations

---

#### [`analyze_results(structured_df)`](./analyse_pipeline.py#L120-L135)
*Location: `analyse_pipeline.py:120-135`*

**Purpose**: Re-analyzes data after user modifications in interactive dashboard.

**Operations**: Recalculates weighted scores, refreshes red flags, updates recommendations
**Parameters**: `structured_df` - Modified DataFrame from UI
**Returns**: Updated final_score, flags, recommendations

---

### Utility Functions

#### [`read_files(uploaded_files)`](./Utils/utils.py#L42-L51)
*Location: `Utils/utils.py:42-51`*
**Purpose**: Batch file processing for multiple document types
**Calls**: [`read_file()`](./Utils/utils.py#L8-L39) for individual file processing

#### [`content_to_json(content)`](./Utils/pdf_file_reader.py#L15-L51) ğŸš§ **[TO BE IMPLEMENTED]**
*Location: `Utils/pdf_file_reader.py:15-51`*  
**Purpose**: Converts raw text to structured startup parameters using AI/LLM
**Current Status**: âš ï¸ Uses hardcoded sample data - **AI integration pending**
**Next Steps**: Integrate with GPT-4/Claude for dynamic content analysis

#### [`convert_raw_to_structured(raw_df)`](./Utils/structured_2_scored_data.py#L69-L146)
*Location: `Utils/structured_2_scored_data.py:69-146`*
**Purpose**: Transforms parameters into scored format with benchmarks
**Key Functions**: Uses [`parse_team()`](./Utils/structured_2_scored_data.py#L44-L51), [`parse_market_size()`](./Utils/structured_2_scored_data.py#L9-L24), [`parse_traction()`](./Utils/structured_2_scored_data.py#L26-L42) for scoring

### Scoring Functions
*All located in [`Utils/structured_2_scored_data.py`](./Utils/structured_2_scored_data.py)*

- **[`parse_team()`](./Utils/structured_2_scored_data.py#L44-L51)**: Team background scoring with IIT/IIM bonuses
- **[`parse_market_size()`](./Utils/structured_2_scored_data.py#L9-L24)**: Market size analysis with B/M regex parsing  
- **[`parse_traction()`](./Utils/structured_2_scored_data.py#L26-L42)**: User growth and MoM metrics evaluation
- **[Weight/Benchmark Configs](./Utils/structured_2_scored_data.py#L106-L137)**: Parameter weights, thresholds, benchmarks

## âš™ï¸ Configuration

### Scoring Parameters
**Parameter Weights** - See [`Utils/structured_2_scored_data.py:117-126`](./Utils/structured_2_scored_data.py#L117-L126)
- All weights sum to 1.0 for normalized scoring
- Team, Market, Traction, Product get 15% each (highest priority)
- Other parameters get 10% each

**Risk Thresholds** - See [`Utils/structured_2_scored_data.py:128-137`](./Utils/structured_2_scored_data.py#L128-L137)
- Minimum acceptable scores for red flag detection
- Default threshold: 3/10 for all parameters

**Industry Benchmarks** - See [`Utils/structured_2_scored_data.py:106-115`](./Utils/structured_2_scored_data.py#L106-L115)
- Sector-specific performance comparisons
- Used for relative scoring and recommendations

### File Processing Configuration
**Supported Formats**: PDF, DOCX, DOC, TXT (see [`Utils/utils.py:15-37`](./Utils/utils.py#L15-L37))
**File Size Limits**: Handled by Streamlit default settings
**OCR Support**: Google Cloud Vision integration available in [`tools/tools.py:50-68`](./tools/tools.py#L50-L68)

### Streamlit UI Components
**Main Interface** - See [`app.py:5-113`](./app.py#L5-L113)
- **Upload Phase** ([lines 15-33](./app.py#L15-L33)): File uploaders with validation
- **Analysis Dashboard** ([lines 35-89](./app.py#L35-L89)): Results display with interactive elements
- **Data Editor** ([lines 49-55](./app.py#L49-L55)): Real-time parameter modification
- **Visualizations** ([lines 78-89](./app.py#L78-L89)): Trend charts and comparisons
- **Action Buttons** ([lines 92-109](./app.py#L92-L109)): Re-analyze, download, navigation

**Session State Management** ([lines 8-11](./app.py#L8-L11)): Persistent data across user interactions


## ğŸ” Troubleshooting

### Common Issues

**1. PDF Processing Errors**
```bash
# Install additional dependencies
pip install PyPDF2 pdfplumber

# For OCR support
pip install google-cloud-vision
```

**2. Streamlit Import Errors**
```bash
# Upgrade Streamlit
pip install --upgrade streamlit

# Clear cache
streamlit cache clear
```

**3. Memory Issues with Large Files**
```python
# Increase file upload limit in .streamlit/config.toml
[server]
maxUploadSize = 200
```

## ğŸ“Š Sample Data

### Input Document Structure
```json
{
  "company_name": "FinTechX",
  "sector": "Finance",
  "founded": "2022",
  "team": "3 founders from IIT Delhi + 10 engineers",
  "market": "Indian SME lending market $50B",
  "traction": "10,000 users, 20% MoM growth",
  "revenue": "INR 2 Cr ARR",
  "unique_selling_point": "AI-driven underwriting with 30% lower default rate",
  "competition": "KreditBee, LendingKart",
  "risks": "Regulatory hurdles, funding dependency"
}
```

### Output Analysis Format
```python
{
  "final_score": 7.8,
  "parameter_scores": {
    "Team_Quality": 8,
    "Market_Size": 9,
    "Traction": 7,
    "Financials": 7,
    "Product_Uniqueness": 8,
    "Competitive_Landscape": 7,
    "Business_Model_Clarity": 7,
    "Risk_Factors": 6
  },
  "red_flags": [
    "Team Score is less than threshold. Refer page No 1",
    "Financial Score is less than benchmark. Refer page no 3"
  ],
  "recommendations": [
    "Strengthen team with industry veterans",
    "Improve financial projections and unit economics"
  ]
}
```
