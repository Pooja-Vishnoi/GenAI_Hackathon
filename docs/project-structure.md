# ðŸ“ Project Structure

## ðŸ“‚ Directory Overview

```
ðŸš€ GenAI_Hackathon/
â”œâ”€â”€ ðŸ–¥ï¸ app.py                    # Main Streamlit application
â”œâ”€â”€ âš™ï¸ analyse_pipeline.py       # Core analysis pipeline
â”œâ”€â”€ ðŸ“‹ README.md                 # Main documentation
â”œâ”€â”€ ðŸ“ readme.md                 # Secondary readme file
â”œâ”€â”€ ðŸ“¦ requirements.txt          # Python dependencies
â”œâ”€â”€ ðŸ __init__.py               # Python package initialization
â”‚
â”œâ”€â”€ ðŸ“š docs/                     # Documentation folder
â”‚   â”œâ”€â”€ ðŸ—ï¸ architecture.md       # System architecture details
â”‚   â”œâ”€â”€ ðŸ”§ api-reference.md      # API documentation
â”‚   â”œâ”€â”€ ðŸ”„ data-flow.md          # Data flow documentation
â”‚   â”œâ”€â”€ âš™ï¸ configuration.md      # Configuration guide
â”‚   â”œâ”€â”€ ðŸ” troubleshooting.md    # Troubleshooting guide
â”‚   â”œâ”€â”€ ðŸŽ¨ UI-UX.md              # UI/UX documentation
â”‚   â”œâ”€â”€ ðŸš€ SETUP_INSTRUCTIONS.md # Installation guide
â”‚   â””â”€â”€ ðŸ“ project-structure.md  # This file
â”‚
â”œâ”€â”€ ðŸ”§ Utils/                    # Utility modules
â”‚   â”œâ”€â”€ ðŸ› ï¸ utils.py              # File processing utilities
â”‚   â”œâ”€â”€ ðŸ“„ pdf_file_reader.py    # PDF content extraction
â”‚   â”œâ”€â”€ ðŸŽ¯ structured_2_scored_data.py  # Scoring algorithms
â”‚   â””â”€â”€ ðŸ§® final_score.py        # Final score calculation
â”‚
â”œâ”€â”€ ðŸ› ï¸ tools/                    # Processing tools
â”‚   â”œâ”€â”€ ðŸ”¨ tools.py              # PDF processing tools
â”‚   â”œâ”€â”€ ðŸ’¬ prompts.py            # AI prompts and templates
â”‚   â””â”€â”€ ðŸ __init__.py           # Package initialization
â”‚
â”œâ”€â”€ ðŸ“Š data/                     # Data and benchmarks
â”‚   â”œâ”€â”€ ðŸ“ˆ sector_benchmarks.csv # Industry benchmarks
â”‚   â”œâ”€â”€ ðŸ“‹ data_extracted.json   # Sample extracted data
â”‚   â”œâ”€â”€ ðŸ”„ data_normalized.json  # Processed data samples
â”‚   â”œâ”€â”€ ðŸ“Š data_score.json       # Scored data results
â”‚   â”œâ”€â”€ ðŸ“ data_score_sample.json # Sample scoring data
â”‚   â””â”€â”€ ðŸ“ archieve/             # Historical data
â”‚       â””â”€â”€ ðŸ“‹ startup_parameters.csv
â”‚
â”œâ”€â”€ ðŸ“¤ input/                    # Sample documents
â”‚   â”œâ”€â”€ ðŸ“Š startup_ptch_deck.pdf # Main startup pitch deck
â”‚   â”œâ”€â”€ ðŸ“ˆ FinTechX_ AI-Powered SME Lending Revolution.pdf # FinTech example
â”‚   â”œâ”€â”€ ðŸ“ transcript.txt        # Call transcript sample
â”‚   â”œâ”€â”€ ðŸ“ pitch_deck_draft.txt  # Text-based pitch deck
â”‚   â”œâ”€â”€ ðŸ“§ email.docx            # Email communication sample
â”‚   â””â”€â”€ ðŸ‘¤ founder_material.docx # Founder background info
â”‚
â””â”€â”€ ðŸ¤– agents/                   # AI agents (future)
    â”œâ”€â”€ ðŸ’¼ investor_agent.py     # Investment analysis agent
    â”œâ”€â”€ ðŸ’¡ recommendation_prompt.py # Recommendation generation
    â””â”€â”€ ðŸ __init__.py           # Package initialization
```

## ðŸ“„ File Descriptions

### ðŸ–¥ï¸ Core Application Files

| **File** | **Purpose** | **Key Functions** |
|----------|-------------|-------------------|
| `app.py` | Main Streamlit web interface | File upload, dashboard display, user interactions |
| `analyse_pipeline.py` | Backend analysis engine | `create_results()`, `analyze_results()`, scoring logic |
| `requirements.txt` | Dependency management | Lists all required Python packages |

### ðŸ”§ Utils Module

| **File** | **Purpose** | **Key Functions** |
|----------|-------------|-------------------|
| `utils.py` | File I/O operations | `read_file()`, `read_files()` - Multi-format file reading |
| `pdf_file_reader.py` | Content extraction | `content_to_json()` - Convert text to structured data |
| `structured_2_scored_data.py` | Scoring algorithms | `parse_team()`, `parse_market_size()`, `parse_traction()` |
| `final_score.py` | Score aggregation | Weighted score calculation |

### ðŸ› ï¸ Tools Module

| **File** | **Purpose** | **Status** |
|----------|-------------|------------|
| `tools.py` | Advanced PDF processing | OCR support, complex extraction |
| `prompts.py` | AI prompt templates | LLM integration prompts |

### ðŸ“Š Data Directory

| **File/Folder** | **Content Type** | **Usage** |
|-----------------|------------------|-----------|
| `sector_benchmarks.csv` | Industry metrics | Comparison benchmarks |
| `data_extracted.json` | Raw extraction | Sample parameter extraction |
| `data_normalized.json` | Normalized data | Processed parameters |
| `data_score.json` | Scoring results | Final scored output |
| `archieve/` | Historical data | Previous analyses |

### ðŸ“¤ Input Directory

| **File** | **Type** | **Purpose** |
|----------|----------|-------------|
| `startup_ptch_deck.pdf` | PDF | Sample pitch deck for testing |
| `FinTechX_*.pdf` | PDF | FinTech startup example |
| `transcript.txt` | Text | Call transcript sample |
| `email.docx` | Word | Email communications |
| `founder_material.docx` | Word | Founder background info |

### ðŸ¤– Agents Module

| **File** | **Purpose** | **Status** |
|----------|-------------|------------|
| `investor_agent.py` | Investment analysis logic | In development |
| `recommendation_prompt.py` | Recommendation generation | Active |

## ðŸ”„ Data Flow Through Structure

```mermaid
graph TD
    A[ðŸ“¤ input/] -->|Upload| B[ðŸ–¥ï¸ app.py]
    B -->|Process| C[âš™ï¸ analyse_pipeline.py]
    C -->|Read| D[ðŸ”§ Utils/utils.py]
    C -->|Extract| E[ðŸ”§ Utils/pdf_file_reader.py]
    C -->|Score| F[ðŸ”§ Utils/structured_2_scored_data.py]
    F -->|Benchmark| G[ðŸ“Š data/sector_benchmarks.csv]
    C -->|Results| B
    B -->|Display| H[ðŸ“Š Dashboard]
```

## ðŸ—ï¸ Module Dependencies

```mermaid
graph LR
    APP[app.py] --> PIPELINE[analyse_pipeline.py]
    PIPELINE --> UTILS[Utils/*]
    PIPELINE --> TOOLS[tools/*]
    PIPELINE --> DATA[data/*]
    UTILS --> AGENTS[agents/*]
    
    style APP fill:#4285f4,color:#fff
    style PIPELINE fill:#34a853,color:#fff
    style UTILS fill:#fbbc05,color:#000
```

## ðŸš€ Adding New Features

### Creating New Scoring Parameters

1. **Add parser function** in `Utils/structured_2_scored_data.py`:
```python
def parse_new_parameter(param_str):
    # Implementation
    return score
```

2. **Update weights** in same file:
```python
weights['New_Parameter'] = 0.10
```

3. **Add to pipeline** in `analyse_pipeline.py`

### Adding New File Formats

1. **Extend `read_file()`** in `Utils/utils.py`:
```python
elif file_extension == '.new':
    # New format processing
    return extracted_text
```

2. **Update supported formats** in `app.py`

### Creating New Agents

1. **Create file** in `agents/` directory
2. **Implement agent logic**
3. **Import in `analyse_pipeline.py`**
4. **Wire up in main pipeline**

## ðŸ“¦ Package Structure

The project follows a modular architecture:

- **Presentation Layer**: `app.py` (Streamlit UI)
- **Business Logic**: `analyse_pipeline.py` (Core processing)
- **Data Access**: `Utils/` (File I/O, data processing)
- **Intelligence**: `agents/` (AI/ML components)
- **Configuration**: `data/` (Benchmarks, samples)
- **Documentation**: `docs/` (All documentation)

## ðŸ”’ File Permissions

Ensure proper permissions:
```bash
chmod 755 *.py           # Executable Python files
chmod 644 *.txt *.json   # Data files
chmod 755 Utils/ tools/  # Directories
```
