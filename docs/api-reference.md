# ğŸ”§ API Reference

## ğŸ“š Core Functions

### ğŸš€ `create_results(uploaded_files)`
*ğŸ“ Location: `analyse_pipeline.py:7-55`*

**ğŸ¯ Purpose**: Main analysis pipeline that processes uploaded files and generates comprehensive startup evaluation.

**ğŸ”„ Process Flow**:
1. ğŸ“– Extract content from files using [`read_files()`](../Utils/utils.py#L42-L51) 
2. ğŸ”„ Convert to structured JSON via [`content_to_json()`](../Utils/pdf_file_reader.py#L15-L51)
3. ğŸ“Š Create parameter DataFrame ([`create_results()` lines 23-28](../analyse_pipeline.py#L23-L28))
4. ğŸ¯ Apply scoring algorithms via [`convert_raw_to_structured()`](../Utils/structured_2_scored_data.py#L69-L146)
5. âš–ï¸ Calculate weighted scores and final rating
6. ğŸš¨ Generate red flags via [`detect_red_flags()`](../analyse_pipeline.py#L88-L110) and ğŸ’¡ recommendations via [`generate_recommendations()`](../analyse_pipeline.py#L112-L118)

**ğŸ“¥ Parameters**: 
- `uploaded_files` - List of Streamlit file objects

**ğŸ“¤ Returns**: 
- `summary_df` - Summary DataFrame with company info
- `results_df` - Detailed results with scores
- `final_score` - Overall weighted score (0-10)
- `flags` - List of red flags detected
- `recommendations` - List of actionable recommendations

**Example Usage**:
```python
summary_df, results_df, final_score, flags, recommendations = create_results(uploaded_files)
```

---

### ğŸ”„ `analyze_results(structured_df)`
*ğŸ“ Location: `analyse_pipeline.py:120-135`*

**ğŸ¯ Purpose**: Re-analyzes data after user modifications in interactive dashboard.

**Operations**: 
- Recalculates weighted scores
- Refreshes red flags
- Updates recommendations

**ğŸ“¥ Parameters**: 
- `structured_df` - Modified DataFrame from UI

**ğŸ“¤ Returns**: 
- `final_score` - Updated overall score
- `flags` - Updated list of red flags
- `recommendations` - Updated recommendations

**Example Usage**:
```python
final_score, flags, recommendations = analyze_results(structured_df)
```

---

## ğŸ“š Utility Functions

### ğŸ“– `read_files(uploaded_files)`
*ğŸ“ Location: `Utils/utils.py:42-51`*

**ğŸ¯ Purpose**: Batch file processing for multiple document types

**ğŸ“¥ Parameters**: 
- `uploaded_files` - List of uploaded file objects

**ğŸ“¤ Returns**: 
- Combined text content from all files

**Calls**: [`read_file()`](../Utils/utils.py#L8-L39) for individual file processing

---

### ğŸ“„ `read_file(file)`
*ğŸ“ Location: `Utils/utils.py:8-39`*

**ğŸ¯ Purpose**: Reads individual file and extracts text content

**ğŸ“¥ Parameters**: 
- `file` - Single file object (PDF, DOCX, or TXT)

**ğŸ“¤ Returns**: 
- Extracted text content as string

**Supported Formats**:
- ğŸ“„ PDF - Using PyPDF2
- ğŸ“ DOCX/DOC - Using python-docx
- ğŸ“„ TXT - UTF-8 text files

---

### ğŸ¤– `content_to_json(content)` ğŸš§ **[TO BE IMPLEMENTED]**
*ğŸ“ Location: `Utils/pdf_file_reader.py:15-51`*

**ğŸ¯ Purpose**: Converts raw text to structured startup parameters using AI/LLM

**ğŸ“¥ Parameters**: 
- `content` - Raw text content from documents

**ğŸ“¤ Returns**: 
- Structured JSON with company parameters

**Current Status**: âš ï¸ Uses hardcoded sample data - **AI integration pending**

**Next Steps**: Integrate with GPT-4/Claude for dynamic content analysis

---

### ğŸ”„ `convert_raw_to_structured(raw_df)`
*ğŸ“ Location: `Utils/structured_2_scored_data.py:69-146`*

**ğŸ¯ Purpose**: Transforms parameters into scored format with benchmarks

**ğŸ“¥ Parameters**: 
- `raw_df` - DataFrame with raw parameter values

**ğŸ“¤ Returns**: 
- DataFrame with scored parameters (1-10 scale)

**Key Functions Used**: 
- [`parse_team()`](../Utils/structured_2_scored_data.py#L44-L51)
- [`parse_market_size()`](../Utils/structured_2_scored_data.py#L9-L24)
- [`parse_traction()`](../Utils/structured_2_scored_data.py#L26-L42)

---

## ğŸ¯ Scoring Functions
*All located in [`Utils/structured_2_scored_data.py`](../Utils/structured_2_scored_data.py)*

### ğŸ‘¥ `parse_team(team_str)`
*ğŸ“ Location: Lines 44-51*

**ğŸ¯ Purpose**: Team background scoring with IIT/IIM bonuses

**ğŸ“¥ Parameters**: 
- `team_str` - String describing team composition

**ğŸ“¤ Returns**: 
- Score (1-10) based on team quality

**Scoring Logic**:
- Base score from team size
- +2 points for IIT/IIM backgrounds
- Maximum score: 10

---

### ğŸŒ `parse_market_size(market_str)`
*ğŸ“ Location: Lines 9-24*

**ğŸ¯ Purpose**: Market size analysis with B/M regex parsing

**ğŸ“¥ Parameters**: 
- `market_str` - String describing market size

**ğŸ“¤ Returns**: 
- Score (1-10) based on TAM size

**Scoring Logic**:
- $50B+ â†’ 10 points
- $10-50B â†’ 8 points
- $1-10B â†’ 6 points
- <$1B â†’ 4 points

---

### ğŸ“ˆ `parse_traction(traction_str)`
*ğŸ“ Location: Lines 26-42*

**ğŸ¯ Purpose**: User growth and MoM metrics evaluation

**ğŸ“¥ Parameters**: 
- `traction_str` - String describing traction metrics

**ğŸ“¤ Returns**: 
- Score (1-10) based on growth metrics

**Scoring Logic**:
- User count evaluation
- MoM growth rate assessment
- Combined weighted score

---

## ğŸ§  Analysis Functions

### ğŸš¨ `detect_red_flags(df, score)`
*ğŸ“ Location: `analyse_pipeline.py:88-110`*

**ğŸ¯ Purpose**: Identifies parameters below acceptable thresholds

**ğŸ“¥ Parameters**: 
- `df` - DataFrame with scored parameters
- `score` - Overall weighted score

**ğŸ“¤ Returns**: 
- List of red flag strings with page references

**Detection Logic**:
- Checks each parameter against threshold (default: 3/10)
- Adds page references for traceability
- Includes overall score warning if < 5

---

### ğŸ’¡ `generate_recommendations(df, flags)`
*ğŸ“ Location: `analyse_pipeline.py:112-118`*

**ğŸ¯ Purpose**: Generates actionable insights based on analysis

**ğŸ“¥ Parameters**: 
- `df` - DataFrame with scored parameters
- `flags` - List of detected red flags

**ğŸ“¤ Returns**: 
- List of recommendation strings

**Recommendation Logic**:
- Parameter-specific suggestions
- Priority-based ordering
- Actionable improvement steps

---

## ğŸ“Š Configuration Functions

### âš–ï¸ Weight & Benchmark Configs
*ğŸ“ Location: `Utils/structured_2_scored_data.py:106-137`*

**Parameter Weights** (Lines 117-126):
```python
weights = {
    'Team_Quality': 0.15,
    'Market_Size': 0.15,
    'Traction': 0.15,
    'Financials': 0.10,
    'Product_Uniqueness': 0.15,
    'Competitive_Landscape': 0.10,
    'Business_Model_Clarity': 0.10,
    'Risk_Factors': 0.10
}
```

**Risk Thresholds** (Lines 128-137):
```python
thresholds = {
    'Team_Quality': 3,
    'Market_Size': 3,
    'Traction': 3,
    'Financials': 3,
    'Product_Uniqueness': 3,
    'Competitive_Landscape': 3,
    'Business_Model_Clarity': 3,
    'Risk_Factors': 3
}
```

---

## ğŸ–¥ï¸ UI Functions

### ğŸ“¤ File Upload Handler
*ğŸ“ Location: `app.py:15-33`*

**Components**:
- Pitch deck uploader (required)
- Call transcript uploader (optional)
- Founder material uploader (optional)

### ğŸ“Š Dashboard Renderer
*ğŸ“ Location: `app.py:35-89`*

**Components**:
- Score display
- Parameter editor
- Charts and visualizations
- Red flags display
- Recommendations panel

### ğŸ”„ Session State Manager
*ğŸ“ Location: `app.py:8-11`*

**Manages**:
- Analysis results
- User modifications
- UI state persistence
