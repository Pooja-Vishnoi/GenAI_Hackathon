# ğŸ—ï¸ Architecture Documentation

## ğŸ¯ Frontend-Backend Separation

The application follows a clear **Frontend-Backend architecture**:

- **ğŸ–¥ï¸ Frontend (`app.py`)**: Streamlit-based UI that handles user interactions, file uploads, and data visualization
- **âš™ï¸ Backend (`analyse_pipeline.py`)**: Core processing engine that performs analysis, scoring, and recommendation generation

```mermaid
graph TB
    subgraph FRONTEND["ğŸ–¥ï¸ FRONTEND - app.py"]
        UI[Streamlit UI]
        FU[File Upload Interface]
        DE[Data Editor]
        VIZ[Visualizations]
        BTN[Action Buttons]
    end
    
    subgraph BACKEND["âš™ï¸ BACKEND - analyse_pipeline.py"]
        CR[create_results]
        AR[analyze_results]
        DF[detect_red_flags]
        GR[generate_recommendations]
    end
    
    UI --> FU
    FU -->|Uploaded Files| CR
    CR -->|Results DataFrame| DE
    DE -->|Modified Data| AR
    AR -->|Updated Scores| VIZ
    BTN -->|Re-analyze| AR
    
    style UI fill:#4285f4,color:#fff
    style CR fill:#34a853,color:#fff
```

## ğŸ”„ Complete Application Flow

```mermaid
flowchart TD
    subgraph FRONTEND["ğŸ–¥ï¸ FRONTEND (app.py)"]
        START([User Opens App]) --> UPLOAD[File Upload UI]
        UPLOAD --> VALIDATE{Files Valid?}
        VALIDATE -->|No| ERROR[Show Error]
        VALIDATE -->|Yes| ANALYZE_BTN[Click Analyze Button]
        
        RESULTS_UI[Display Results Dashboard]
        EDIT_UI[Data Editor Interface]
        REANALYZE_BTN[Re-analyze Button]
    end
    
    subgraph BACKEND["âš™ï¸ BACKEND (analyse_pipeline.py)"]
        CREATE_RESULTS[create_results]
        ANALYZE_RESULTS[analyze_results]
        
        subgraph UTILS["ğŸ“š Utils Functions"]
            READ_FILES[read_files]
            CONTENT_JSON[content_to_json]
            CONVERT_STRUCT[convert_raw_to_structured]
        end
        
        subgraph ANALYSIS["ğŸ§  Analysis Functions"]
            DETECT_RED[detect_red_flags]
            DETECT_GREEN[detect_green_flags]
            GEN_REC[generate_recommendations]
        end
    end
    
    ANALYZE_BTN -->|Call| CREATE_RESULTS
    CREATE_RESULTS --> READ_FILES
    READ_FILES --> CONTENT_JSON
    CONTENT_JSON --> CONVERT_STRUCT
    CONVERT_STRUCT --> DETECT_RED
    CONVERT_STRUCT --> DETECT_GREEN
    DETECT_RED --> GEN_REC
    DETECT_GREEN --> GEN_REC
    
    CREATE_RESULTS -->|Return Results| RESULTS_UI
    RESULTS_UI --> EDIT_UI
    EDIT_UI --> REANALYZE_BTN
    REANALYZE_BTN -->|Call| ANALYZE_RESULTS
    ANALYZE_RESULTS -->|Update| RESULTS_UI
    
    style UPLOAD fill:#4285f4,color:#fff
    style CREATE_RESULTS fill:#34a853,color:#fff
    style ANALYZE_RESULTS fill:#fbbc05,color:#000
```

## ğŸ›ï¸ High-Level System Overview

```mermaid
graph LR
    A[ğŸ“„ Documents] --> B[ğŸ–¥ï¸ Frontend<br/>app.py]
    B --> C[âš™ï¸ Backend<br/>analyse_pipeline.py]
    C --> D[ğŸ§  Analysis Engine]
    D --> B
    B --> E[ğŸ“Š Interactive Dashboard]
```

## ğŸ“‹ Key Function Calls Between Frontend & Backend

| **Frontend Action (app.py)** | **Backend Function Called** | **Purpose** | **Returns** |
|------------------------------|----------------------------|------------|-------------|
| **User clicks "ğŸ” Analyze"** | `create_results(uploaded_files)` | Initial document analysis | summary_df, results_df, score, flags, recommendations |
| **User edits data in UI** | `analyze_results(structured_df)` | Re-calculate scores | final_score, flags, recommendations |
| **User clicks "ğŸ”„ Re-analyze"** | `analyze_results(structured_df)` | Refresh analysis | final_score, flags, recommendations |
| **Dashboard loads** | Uses returned DataFrames | Display results | N/A - uses stored session state |

## ğŸ”§ Detailed Architecture Layers

### ğŸ¨ Layer 1: Frontend User Interface (`app.py`)
```mermaid
graph TB
    UI[Streamlit Web App - app.py]
    UP[File Upload - Lines 538-584]
    DA[Dashboard Display - Lines 749-823]
    ME[Metrics Display - Lines 589-640]
    IN[Insights Display - Lines 645-682]
    
    UI --> UP
    UI --> DA
    UI --> ME
    UI --> IN
```

### âš™ï¸ Layer 2: Backend Processing Pipeline (`analyse_pipeline.py`)
```mermaid
graph LR
    INPUT[Input Files] --> CR[create_results - Lines 18-67]
    CR --> RF[read_files]
    RF --> PE[content_to_json]
    PE --> SC[convert_raw_to_structured]
    SC --> AR[analyze_results - Lines 151-167]
```

### ğŸ§  Layer 3: Analysis Engine (8 Parameters)
```mermaid
graph TB
    SC[Scoring Engine] --> PARAMS{Parameter Analysis}
    
    PARAMS --> TS[Team Quality]
    PARAMS --> MS[Market Size]
    PARAMS --> TR[Traction]
    PARAMS --> FS[Financials]
    PARAMS --> PS[Product Uniqueness]
    PARAMS --> CS[Competition Analysis]
    PARAMS --> BS[Business Model]
    PARAMS --> RS[Risk Factors]
```

### ğŸ¤– Layer 4: Intelligence & Output
```mermaid
graph TB
    SCORES[Parameter Scores] --> RF_ENGINE[Red Flag Detector]
    SCORES --> REC_ENGINE[Recommendation Engine]
    BENCH[Benchmarks] --> REC_ENGINE
    
    RF_ENGINE --> OUTPUT[Final Results]
    REC_ENGINE --> OUTPUT
    
    OUTPUT --> DASHBOARD[Return to Frontend]
```

## ğŸ§© Detailed Component Architecture

### ğŸ¨ 1. User Interface Layer
- **ğŸ–¥ï¸ [`Streamlit Web App`](../app.py)** - Main application interface
  - **ğŸ“¤ [File Upload Interface](../app.py#L18-L23)**: Multi-format document upload with validation
  - **ğŸ“Š [Interactive Dashboard](../app.py#L35-L89)**: Real-time results display and editing
  - **ğŸ“ˆ [Data Visualizations](../app.py#L78-L89)**: Charts, trends, and benchmark comparisons

### âš™ï¸ 2. Processing Pipeline Layer
- **ğŸ”„ [`Main Pipeline`](../analyse_pipeline.py#L7-L55)** - Orchestrates entire analysis workflow
  - **ğŸ“– [`File Reader`](../Utils/utils.py#L42-L51)** - Batch processing of uploaded documents
  - **ğŸ” [`Parameter Extractor`](../Utils/pdf_file_reader.py#L15-L51)** - AI-powered content analysis
  - **ğŸ¯ [`Scoring Engine`](../Utils/structured_2_scored_data.py#L69-L146)** - Transforms text to numerical scores

### ğŸ§  3. Analysis Engine - 8-Parameter Evaluation System
- **ğŸ‘¥ [`Team Scorer`](../Utils/structured_2_scored_data.py#L44-L51)** - Educational background + experience analysis
- **ğŸŒ [`Market Analyzer`](../Utils/structured_2_scored_data.py#L9-L24)** - TAM size evaluation with regex parsing
- **ğŸ“ˆ [`Traction Evaluator`](../Utils/structured_2_scored_data.py#L26-L42)** - User growth + MoM metrics
- **ğŸ’° [Financial Scorer](../Utils/structured_2_scored_data.py#L87)** - Revenue, ARR, burn rate assessment
- **ğŸš€ [Product Scorer](../Utils/structured_2_scored_data.py#L88)** - Innovation, differentiation, AI/tech analysis
- **ğŸ† [Competition Analyzer](../Utils/structured_2_scored_data.py#L89-L91)** - Market saturation and competitive positioning
- **ğŸ’¼ [Business Model Scorer](../Utils/structured_2_scored_data.py#L92)** - Revenue model clarity and scalability
- **âš ï¸ [Risk Assessor](../Utils/structured_2_scored_data.py#L93)** - Regulatory, operational, market risk evaluation

### ğŸ¤– 4. Intelligence Layer - Advanced Analytics
- **ğŸš¨ [`Red Flag Detector`](../analyse_pipeline.py#L88-L110)** - Threshold-based risk identification
- **ğŸ’¡ [`Recommendation Engine`](../analyse_pipeline.py#L112-L118)** - Actionable insights generation
- **ğŸ“Š [`Benchmark Comparator`](../data/sector_benchmarks.csv)** - Industry-specific performance analysis

### ğŸ“š 5. Data Layer - Information Management
- **ğŸ“„ Input Documents** - Multi-format file processing (PDF, DOCX, TXT)
- **ğŸ“Š Benchmark Data** - Sector-specific performance metrics
- **âš™ï¸ Configuration** - Parameter weights, thresholds, scoring rules
- **ğŸ“‹ Analysis Results** - Structured output with scores, flags, recommendations
